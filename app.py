import streamlit as st
import os
import time
import json
import random
import asyncio
import edge_tts
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from langchain_community.vectorstores import FAISS
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter 
from langchain.schema import Document 
from langchain.chains import create_retrieval_chain, create_history_aware_retriever
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage
from google.api_core.exceptions import InvalidArgument
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# --- å¼ºåˆ¶ä»£ç† (å¦‚æœä½ çš„è¯­éŸ³ç”Ÿæˆå¤±è´¥ï¼Œè¯·å–æ¶ˆä¸‹é¢ä¸¤è¡Œçš„æ³¨é‡Šå¹¶ä¿®æ”¹ç«¯å£) ---
# os.environ["http_proxy"] = "http://127.0.0.1:7890"
# os.environ["https_proxy"] = "http://127.0.0.1:7890"

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="å—å¸ˆä¹¦æˆ¿", page_icon="ğŸµ", layout="wide")

NAN_QUOTES = [
    "ä¸–ä¸Šæœ¬æ— äº‹ï¼Œåº¸äººè‡ªæ‰°ä¹‹ã€‚", "åº”æ— æ‰€ä½ï¼Œè€Œç”Ÿå…¶å¿ƒã€‚", "èƒ½æ§åˆ¶æ—©æ™¨çš„äººï¼Œå°±èƒ½æ§åˆ¶äººç”Ÿã€‚",
    "é™åä¿®é“ä¸é•¿ç”Ÿä¸è€ï¼Œéƒ½åœ¨è¿™ä¸ªâ€œé™â€å­—ã€‚", "äººç”Ÿæœ€é«˜å¢ƒç•Œæ˜¯ï¼šä½›ä¸ºå¿ƒï¼Œé“ä¸ºéª¨ï¼Œå„’ä¸ºè¡¨ï¼Œå¤§åº¦çœ‹ä¸–ç•Œã€‚",
    "åŠŸæˆã€åé‚ã€èº«é€€ï¼Œå¤©ä¹‹é“ã€‚", "çŸ¥æ­¢è€Œåæœ‰å®šï¼Œå®šè€Œåèƒ½é™ï¼Œé™è€Œåèƒ½å®‰ã€‚",
    "çœŸæ­£çš„ä¿®è¡Œï¼Œä¸ç¦»æ—¥å¸¸ç”Ÿæ´»ã€‚", "å¿ƒå¹³æ°”å’Œï¼Œå°±æ˜¯é“ã€‚", "å¤§ä¸ˆå¤«å¤„å…¶åšï¼Œä¸å±…å…¶è–„ï¼›å¤„å…¶å®ï¼Œä¸å±…å…¶åã€‚",
    "è‹±é›„åˆ°è€çš†å½’ä½›ï¼Œå®¿å°†è¿˜å±±ä¸è®ºå…µã€‚", "å¤šè¨€æ•°ç©·ï¼Œä¸å¦‚å®ˆä¸­ã€‚"
]

st.markdown("""
<style>
    .stApp {
        background-color: #F9F7F1;
        background-image: url("https://www.transparenttextures.com/patterns/rice-paper-2.png");
        font-family: "æ¥·ä½“", "KaiTi", "Songti SC", serif;
    }
    [data-testid="stChatMessage"]:nth-child(odd) { background-color: rgba(239, 239, 239, 0.7); border-radius: 15px; padding: 15px; border: 1px solid #D3D3D3; }
    [data-testid="stChatMessage"]:nth-child(even) { background-color: rgba(240, 230, 210, 0.8); border-radius: 15px; padding: 15px; border-left: 4px solid #8B4513; box-shadow: 2px 2px 5px rgba(0,0,0,0.1); }
    h1 { color: #4A3B2A; text-align: center; font-weight: bold; letter-spacing: 2px; padding-bottom: 10px; border-bottom: 2px solid #8B4513; display: inline-block; }
    .title-container { text-align: center; margin-bottom: 30px; }
    [data-testid="stSidebar"] { background-color: #F4EFE5; border-right: 1px solid #D8CFC4; }
    .quote-card { background-color: #FDFBF7; border: 2px solid #8B4513; border-radius: 8px; padding: 20px; text-align: center; font-size: 1.3em; font-weight: bold; color: #5C4033; box-shadow: 3px 3px 8px rgba(139, 69, 19, 0.2); position: relative; margin-bottom: 20px; }
    .quote-card::before, .quote-card::after { content: 'â€¢'; color: #8B4513; font-size: 2em; position: absolute; top: -15px; }
    .quote-card::before { left: 10px; } .quote-card::after { right: 10px; }
    .stButton button { background-color: #F0E6D2; border: 1px solid #8B4513; color: #5C4033; }
    .stButton button:hover { background-color: #E6D8B8; border-color: #5C4033; color: #3E2B22; }
    #MainMenu {visibility: hidden;} footer {visibility: hidden;} header {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

st.markdown("<div class='title-container'><h1>ğŸµ å—å¸ˆä¹¦æˆ¿</h1></div>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center; color: #777; font-size: 1em; font-style: italic;'>â€”â€” æ­¤æ—¶æ­¤å¤„ï¼Œè°ƒæ¯é™å¿ƒï¼Œä¸å—å¸ˆå¯¹è¯ â€”â€”</p>", unsafe_allow_html=True)

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.markdown("## ğŸ ä¹¦æˆ¿ä¸€éš…")
    st.markdown("### ğŸ“œ ä»Šæ—¥å‚æ‚Ÿ")
    if "daily_quote" not in st.session_state:
        st.session_state.daily_quote = random.choice(NAN_QUOTES)
    st.markdown(f"<div class='quote-card'>â€œ{st.session_state.daily_quote}â€</div><p style='text-align: right; color: #999; font-size: 0.9em;'>â€”â€” å—æ€€ç‘¾</p>", unsafe_allow_html=True)
    st.markdown("---")
    st.markdown("### ğŸµ ä¼´è¯»ç´éŸµ")
    bgm_path = "assets/bgm.mp3"
    audio_source = bgm_path if os.path.exists(bgm_path) else "https://www.soundhelix.com/examples/mp3/SoundHelix-Song-1.mp3"
    st.audio(audio_source, format="audio/mp3", start_time=0)
    st.caption("ğŸ’¡ å»ºè®®ç‚¹å‡»æ’­æ”¾åï¼Œå°†éŸ³é‡è°ƒè‡³è½»æŸ”ã€‚")

# --- åŠŸèƒ½å‡½æ•°å®šä¹‰åŒº ---

# 1. è¯­éŸ³ç”Ÿæˆå‡½æ•°
async def generate_speech(text, output_file="speech_output.mp3"):
    """ä½¿ç”¨ Edge TTS ç”Ÿæˆè¯­éŸ³ï¼ŒåŒ…å«é”™è¯¯å¤„ç†"""
    VOICE = "zh-CN-YunzeNeural"
    try:
        communicate = edge_tts.Communicate(text, VOICE)
        await communicate.save(output_file)
        return True 
    except Exception as e:
        print(f"âš ï¸ è¯­éŸ³ç”Ÿæˆå¤±è´¥: {e}")
        return False

# 2. æ—¥å¿—è®°å½•å‡½æ•°
def save_to_logs(user_question, ai_answer, sources):
    """å°†å¯¹è¯è®°å½•å†™å…¥ Google Sheets"""
    try:
        if "gcp_service_account" not in st.secrets:
            return # æœªé…ç½®åˆ™é™é»˜è·³è¿‡

        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds_dict = dict(st.secrets["gcp_service_account"])
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        client = gspread.authorize(creds)
        
        # å°è¯•æ‰“å¼€è¡¨æ ¼ï¼Œå¦‚æœæ‰¾ä¸åˆ°å¯èƒ½ä¼šæŠ¥é”™ï¼Œæ‰€ä»¥åŠ  try
        sheet = client.open("å—å¸ˆä¹¦æˆ¿æ—¥å¿—").sheet1
        
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
        source_str = "; ".join([f"{doc.metadata.get('source')}Â·{doc.metadata.get('chapter')}" for doc in sources]) if sources else "æ— å¼•ç”¨"
        
        sheet.append_row([timestamp, user_question, ai_answer, source_str])
        print("âœ… æ—¥å¿—å·²è®°å½•")
    except Exception as e:
        print(f"âŒ æ—¥å¿—è®°å½•å¤±è´¥: {e}")

# 3. è¿½é—®ç”Ÿæˆå‡½æ•°
def get_suggestions(answer_text, llm_engine):
    if not llm_engine: return []
    try:
        prompt = f"åŸºäºå›ç­”ï¼š'{answer_text[:500]}...'ï¼Œç”Ÿæˆ3ä¸ªç®€çŸ­è¿½é—®ã€‚åªè¿”å›é—®é¢˜ï¼Œæ¯è¡Œä¸€ä¸ªã€‚"
        res = llm_engine.invoke(prompt)
        return [q.strip() for q in res.content.split('\n') if q.strip()][:3]
    except: return []

# --- RAG ç³»ç»Ÿåˆå§‹åŒ– ---

@st.cache_resource
def initialize_rag():
    if "GOOGLE_API_KEY" not in st.secrets: st.error("è¯·é…ç½® API Key"); return None
    api_key = st.secrets["GOOGLE_API_KEY"]
    
    # å®šä¹‰ LLM (æ³¨æ„è¿™é‡Œä¿®æ­£äº†æ¨¡å‹åç§°)
    llm = ChatGoogleGenerativeAI(
        model="gemini-3-pro-preview", 
        temperature=0.7, 
        google_api_key=api_key,
        safety_settings={HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE, HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE, HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE}
    )
    
    embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004", google_api_key=api_key)
    index_path = "faiss_index"
    
    vectorstore = None
    if os.path.exists(index_path):
        try: vectorstore = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True); st.sidebar.success("âœ… çŸ¥è¯†åº“å·²åŠ è½½")
        except: pass
    
    if vectorstore is None:
        json_path = "data/nan_books.json"
        if not os.path.exists(json_path): st.error("æ•°æ®ç¼ºå¤±"); return None
        docs = []
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
            for item in data:
                docs.append(Document(page_content=item.get("text", ""), metadata={"source": item.get("source", ""), "chapter": item.get("chapter", "")}))
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
        splits = text_splitter.split_documents(docs)
        vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
        vectorstore.save_local(index_path)

    retriever = vectorstore.as_retriever()
    
    # å†å²æ„ŸçŸ¥æ£€ç´¢å™¨
    context_system_prompt = "ç»™å®šå¯¹è¯å†å²å’Œæœ€æ–°æé—®ï¼Œå°†å…¶æ”¹å†™ä¸ºç‹¬ç«‹é—®é¢˜ã€‚ä¸è¦å›ç­”ï¼Œåªæ”¹å†™ã€‚"
    context_prompt = ChatPromptTemplate.from_messages([("system", context_system_prompt), MessagesPlaceholder("chat_history"), ("human", "{input}")])
    history_retriever = create_history_aware_retriever(llm, retriever, context_prompt)

    # é—®ç­”é“¾
    qa_system_prompt = (
        "ä½ æ˜¯å—æ€€ç‘¾ï¼ˆå—å¸ˆï¼‰ã€‚è¯­æ°”æ…ˆæ‚²ã€é€šä¿—ã€å¹½é»˜ã€‚è‹æ ¼æ‹‰åº•å¼æ•™å­¦ã€‚"
        "å¿…é¡»åŸºäº Context å›ç­”ï¼ŒContext å«ä¹¦åç« èŠ‚å¯å¼•ç”¨ã€‚"
        "\n\nå‚è€ƒèµ„æ–™ (Context):\n{context}"
    )
    qa_prompt = ChatPromptTemplate.from_messages([("system", qa_system_prompt), MessagesPlaceholder("chat_history"), ("human", "{input}")])
    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)
    
    rag_chain = create_retrieval_chain(history_retriever, question_answer_chain)

    return rag_chain, llm

rag_setup = initialize_rag()
if rag_setup: rag_chain, llm_engine = rag_setup
else: rag_chain, llm_engine = None, None

# --- èŠå¤©äº¤äº’é€»è¾‘ ---

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "å“å‘€ï¼Œéšä¾¿åã€‚ä»Šå¤©å¿ƒé‡Œæœ‰ä»€ä¹ˆæ”¾ä¸ä¸‹çš„å—ï¼Ÿ"}]

for msg in st.session_state.messages:
    avatar = "ğŸµ" if msg["role"] == "assistant" else "ğŸ‘¤"
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])
        if "audio_path" in msg and os.path.exists(msg["audio_path"]):
             st.audio(msg["audio_path"], format="audio/mp3")

user_input = st.chat_input("è¯·åœ¨æ­¤è¾“å…¥æ‚¨ä¸å—å¸ˆçš„å¯¹è¯...")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user", avatar="ğŸ‘¤"): st.markdown(user_input)

    with st.chat_message("assistant", avatar="ğŸµ"):
        message_placeholder = st.empty()
        if rag_chain:
            with st.spinner("å—å¸ˆæ­£åœ¨æ²‰æ€..."):
                try:
                    chat_history = []
                    for msg in st.session_state.messages[:-1]:
                        if msg["role"] == "user": chat_history.append(HumanMessage(content=msg["content"]))
                        else: chat_history.append(AIMessage(content=msg["content"]))
                    
                    response = rag_chain.invoke({"input": user_input, "chat_history": chat_history})
                    answer = response["answer"]
                    source_documents = response["context"]
                    
                    message_placeholder.markdown(answer)

                    with st.expander("ğŸ” ç‚¹å‡»æŸ¥çœ‹å‡ºå¤„"):
                        if source_documents:
                            for i, doc in enumerate(source_documents):
                                book = doc.metadata.get("source", "æœªçŸ¥")
                                chap = doc.metadata.get("chapter", "")
                                st.markdown(f"**ğŸ“– {book} Â· {chap}**"); st.caption(doc.page_content); st.markdown("---")
                        else: st.caption("é€šç”¨æ™ºæ…§å›ç­”ï¼Œæ— ç›´æ¥å¼•ç”¨ã€‚")
                    
                    # ç”Ÿæˆè¯­éŸ³
                    audio_file = f"speech_{int(time.time())}.mp3"
                    is_audio_success = asyncio.run(generate_speech(answer[:300], audio_file))

                    # è®°å½•æ—¥å¿—
                    save_to_logs(user_input, answer, source_documents)
                    
                    # å­˜å‚¨å†å²
                    msg_data = {"role": "assistant", "content": answer}
                    if is_audio_success:
                        st.audio(audio_file, format="audio/mp3")
                        msg_data["audio_path"] = audio_file
                    
                    st.session_state.messages.append(msg_data)
                    
                    # ç”Ÿæˆè¿½é—®
                    suggestions = get_suggestions(answer, llm_engine)
                    st.session_state.current_suggestions = suggestions
                    
                except Exception as e:
                    message_placeholder.markdown(f"è€å¤´å­ç³Šæ¶‚äº†ï¼ˆ{e}ï¼‰")
        else:
            message_placeholder.markdown("API æœªè¿æ¥")

# è¿½é—®æŒ‰é’®
if st.session_state.messages and st.session_state.messages[-1]["role"] == "assistant":
    if "current_suggestions" in st.session_state and st.session_state.current_suggestions:
        st.markdown("### ğŸ¤” æ‚¨å¯èƒ½æƒ³é—®ï¼š")
        cols = st.columns(3)
        for i, question in enumerate(st.session_state.current_suggestions):
            if cols[i].button(question, key=f"sugg_{i}"):
                st.session_state.messages.append({"role": "user", "content": question})
                st.session_state.current_suggestions = []
                st.rerun()
