import streamlit as st
import os
import time
import json
import random
import asyncio
import edge_tts
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from langchain_community.vectorstores import FAISS
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter 
from langchain.schema import Document 
from langchain.chains import create_retrieval_chain, create_history_aware_retriever
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage
from google.api_core.exceptions import InvalidArgument
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# --- å¼ºåˆ¶ä»£ç† (å¦‚æœä½ çš„è¯­éŸ³ç”Ÿæˆå¤±è´¥ï¼Œè¯·å–æ¶ˆä¸‹é¢ä¸¤è¡Œçš„æ³¨é‡Šå¹¶ä¿®æ”¹ç«¯å£) ---
# os.environ["http_proxy"] = "http://127.0.0.1:7890"
# os.environ["https_proxy"] = "http://127.0.0.1:7890"

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="å—å¸ˆä¹¦æˆ¿", page_icon="ğŸµ", layout="wide")

NAN_QUOTES = [
    "ä¸–ä¸Šæœ¬æ— äº‹ï¼Œåº¸äººè‡ªæ‰°ä¹‹ã€‚", "åº”æ— æ‰€ä½ï¼Œè€Œç”Ÿå…¶å¿ƒã€‚", "èƒ½æ§åˆ¶æ—©æ™¨çš„äººï¼Œå°±èƒ½æ§åˆ¶äººç”Ÿã€‚",
    "é™åä¿®é“ä¸é•¿ç”Ÿä¸è€ï¼Œéƒ½åœ¨è¿™ä¸ªâ€œé™â€å­—ã€‚", "äººç”Ÿæœ€é«˜å¢ƒç•Œæ˜¯ï¼šä½›ä¸ºå¿ƒï¼Œé“ä¸ºéª¨ï¼Œå„’ä¸ºè¡¨ï¼Œå¤§åº¦çœ‹ä¸–ç•Œã€‚",
    "åŠŸæˆã€åé‚ã€èº«é€€ï¼Œå¤©ä¹‹é“ã€‚", "çŸ¥æ­¢è€Œåæœ‰å®šï¼Œå®šè€Œåèƒ½é™ï¼Œé™è€Œåèƒ½å®‰ã€‚",
    "çœŸæ­£çš„ä¿®è¡Œï¼Œä¸ç¦»æ—¥å¸¸ç”Ÿæ´»ã€‚", "å¿ƒå¹³æ°”å’Œï¼Œå°±æ˜¯é“ã€‚", "å¤§ä¸ˆå¤«å¤„å…¶åšï¼Œä¸å±…å…¶è–„ï¼›å¤„å…¶å®ï¼Œä¸å±…å…¶åã€‚",
    "è‹±é›„åˆ°è€çš†å½’ä½›ï¼Œå®¿å°†è¿˜å±±ä¸è®ºå…µã€‚", "å¤šè¨€æ•°ç©·ï¼Œä¸å¦‚å®ˆä¸­ã€‚"
]

st.markdown("""
<style>
    .stApp {
        background-color: #F9F7F1;
        background-image: url("https://www.transparenttextures.com/patterns/rice-paper-2.png");
        font-family: "æ¥·ä½“", "KaiTi", "Songti SC", serif;
    }
    [data-testid="stChatMessage"]:nth-child(odd) { background-color: rgba(239, 239, 239, 0.7); border-radius: 15px; padding: 15px; border: 1px solid #D3D3D3; }
    [data-testid="stChatMessage"]:nth-child(even) { background-color: rgba(240, 230, 210, 0.8); border-radius: 15px; padding: 15px; border-left: 4px solid #8B4513; box-shadow: 2px 2px 5px rgba(0,0,0,0.1); }
    h1 { color: #4A3B2A; text-align: center; font-weight: bold; letter-spacing: 2px; padding-bottom: 10px; border-bottom: 2px solid #8B4513; display: inline-block; }
    .title-container { text-align: center; margin-bottom: 30px; }
    [data-testid="stSidebar"] { background-color: #F4EFE5; border-right: 1px solid #D8CFC4; }
    .quote-card { background-color: #FDFBF7; border: 2px solid #8B4513; border-radius: 8px; padding: 20px; text-align: center; font-size: 1.3em; font-weight: bold; color: #5C4033; box-shadow: 3px 3px 8px rgba(139, 69, 19, 0.2); position: relative; margin-bottom: 20px; }
    .quote-card::before, .quote-card::after { content: 'â€¢'; color: #8B4513; font-size: 2em; position: absolute; top: -15px; }
    .quote-card::before { left: 10px; } .quote-card::after { right: 10px; }
    .stButton button { background-color: #F0E6D2; border: 1px solid #8B4513; color: #5C4033; }
    .stButton button:hover { background-color: #E6D8B8; border-color: #5C4033; color: #3E2B22; }
    #MainMenu {visibility: hidden;} footer {visibility: hidden;} header {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

st.markdown("<div class='title-container'><h1>ğŸµ å—å¸ˆä¹¦æˆ¿</h1></div>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center; color: #777; font-size: 1em; font-style: italic;'>â€”â€” æ­¤æ—¶æ­¤å¤„ï¼Œè°ƒæ¯é™å¿ƒï¼Œä¸å—å¸ˆå¯¹è¯ â€”â€”</p>", unsafe_allow_html=True)

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.markdown("## ğŸ ä¹¦æˆ¿ä¸€éš…")
    st.markdown("### ğŸ“œ ä»Šæ—¥å‚æ‚Ÿ")
    if "daily_quote" not in st.session_state:
        st.session_state.daily_quote = random.choice(NAN_QUOTES)
    st.markdown(f"<div class='quote-card'>â€œ{st.session_state.daily_quote}â€</div><p style='text-align: right; color: #999; font-size: 0.9em;'>â€”â€” å—æ€€ç‘¾</p>", unsafe_allow_html=True)
    st.markdown("---")
    st.markdown("### ğŸµ ä¼´è¯»ç´éŸµ")
    bgm_path = "assets/bgm.mp3"
    audio_source = bgm_path if os.path.exists(bgm_path) else "https://www.soundhelix.com/examples/mp3/SoundHelix-Song-1.mp3"
    st.audio(audio_source, format="audio/mp3", start_time=0)
    st.caption("ğŸ’¡ å»ºè®®ç‚¹å‡»æ’­æ”¾åï¼Œå°†éŸ³é‡è°ƒè‡³è½»æŸ”ã€‚")

# --- åŠŸèƒ½å‡½æ•°å®šä¹‰åŒº ---

# 1. è¯­éŸ³ç”Ÿæˆå‡½æ•°
async def generate_speech(text, output_file="speech_output.mp3"):
    """ä½¿ç”¨ Edge TTS ç”Ÿæˆè¯­éŸ³ï¼ŒåŒ…å«é”™è¯¯å¤„ç†"""
    VOICE = "zh-CN-YunzeNeural"
    try:
        communicate = edge_tts.Communicate(text, VOICE)
        await communicate.save(output_file)
        return True 
    except Exception as e:
        print(f"âš ï¸ è¯­éŸ³ç”Ÿæˆå¤±è´¥: {e}")
        return False

# 2. æ—¥å¿—è®°å½•å‡½æ•°
def save_to_logs(user_question, ai_answer, sources):
    """å°†å¯¹è¯è®°å½•å†™å…¥ Google Sheets"""
    try:
        if "gcp_service_account" not in st.secrets:
            return # æœªé…ç½®åˆ™é™é»˜è·³è¿‡

        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds_dict = dict(st.secrets["gcp_service_account"])
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        client = gspread.authorize(creds)
        
        # å°è¯•æ‰“å¼€è¡¨æ ¼ï¼Œå¦‚æœæ‰¾ä¸åˆ°å¯èƒ½ä¼šæŠ¥é”™ï¼Œæ‰€ä»¥åŠ  try
        sheet = client.open("å—å¸ˆä¹¦æˆ¿æ—¥å¿—").sheet1
        
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
        source_str = "; ".join([f"{doc.metadata.get('source')}Â·{doc.metadata.get('chapter')}" for doc in sources]) if sources else "æ— å¼•ç”¨"
        
        sheet.append_row([timestamp, user_question, ai_answer, source_str])
        print("âœ… æ—¥å¿—å·²è®°å½•")
    except Exception as e:
        print(f"âŒ æ—¥å¿—è®°å½•å¤±è´¥: {e}")

# 3. è¿½é—®ç”Ÿæˆå‡½æ•°
def get_suggestions(answer_text, llm_engine):
    if not llm_engine: return []
    try:
        prompt = f"åŸºäºå›ç­”ï¼š'{answer_text[:500]}...'ï¼Œç”Ÿæˆ3ä¸ªç®€çŸ­è¿½é—®ã€‚åªè¿”å›é—®é¢˜ï¼Œæ¯è¡Œä¸€ä¸ªã€‚"
        res = llm_engine.invoke(prompt)
        return [q.strip() for q in res.content.split('\n') if q.strip()][:3]
    except: return []

# --- RAG ç³»ç»Ÿåˆå§‹åŒ– ---

@st.cache_resource
def initialize_rag():
    if "GOOGLE_API_KEY" not in st.secrets: st.error("è¯·é…ç½® API Key"); return None
    api_key = st.secrets["GOOGLE_API_KEY"]
    
    # å®šä¹‰ LLM (æ³¨æ„è¿™é‡Œä¿®æ­£äº†æ¨¡å‹åç§°)
    llm = ChatGoogleGenerativeAI(
        model="gemini-3-pro-preview", 
        temperature=0.7, 
        google_api_key=api_key,
        safety_settings={HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE, HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE, HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE}
    )
    
    embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004", google_api_key=api_key)
    index_path = "faiss_index"
    
    vectorstore = None
    if os.path.exists(index_path):
        try: vectorstore = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True); st.sidebar.success("âœ… çŸ¥è¯†åº“å·²åŠ è½½")
        except: pass
    
    if vectorstore is None:
        json_path = "data/nan_books.json"
        if not os.path.exists(json_path): st.error("æ•°æ®ç¼ºå¤±"); return None
        docs = []
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
            for item in data:
                docs.append(Document(page_content=item.get("text", ""), metadata={"source": item.get("source", ""), "chapter": item.get("chapter", "")}))
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
        splits = text_splitter.split_documents(docs)
        vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
        vectorstore.save_local(index_path)

    retriever = vectorstore.as_retriever()
    
    # å†å²æ„ŸçŸ¥æ£€ç´¢å™¨
    context_system_prompt = "ç»™å®šå¯¹è¯å†å²å’Œæœ€æ–°æé—®ï¼Œå°†å…¶æ”¹å†™ä¸ºç‹¬ç«‹é—®é¢˜ã€‚ä¸è¦å›ç­”ï¼Œåªæ”¹å†™ã€‚"
    context_prompt = ChatPromptTemplate.from_messages([("system", context_system_prompt), MessagesPlaceholder("chat_history"), ("human", "{input}")])
    history_retriever = create_history_aware_retriever(llm, retriever, context_prompt)

    # é—®ç­”é“¾
    qa_system_prompt = (
    """
    ä½ ç°åœ¨æ˜¯å—æ€€ç‘¾å…ˆç”Ÿï¼ˆå¤§å®¶éƒ½å°Šç§°ä½ ä¸ºâ€œå—å¸ˆâ€ï¼‰ã€‚
    ä½ æ­£åœ¨ä¹¦æˆ¿é‡Œï¼Œä¸ä¸€ä½å‰æ¥æ±‚æ•™çš„åå­¦ï¼ˆç”¨æˆ·ï¼‰é—²èŠã€‚

    ### 1. è¯­è¨€é£æ ¼ï¼ˆæ ¸å¿ƒéŸµå‘³ï¼‰
    * **ç™½è¯ä¸å¤æ–‡å¤¹æ‚**ï¼šç”¨æœ€é€šä¿—çš„å¤§ç™½è¯è®²é“ç†ï¼Œä½†å…³é”®å¤„è¦ä¿¡æ‰‹æ‹ˆæ¥ä¸€å¥ç»å…¸ï¼ˆå„’é‡Šé“çš†å¯ï¼‰ï¼Œç„¶åç«‹é©¬ç”¨å¤§ç™½è¯è§£é‡Šã€‚
    * **å£è¯­åŒ–é‡**ï¼šå¤šç”¨æ„Ÿå¹è¯å’Œè¯­æ°”è¯ï¼Œå¦‚â€œå“å‘€â€ã€â€œé‚£ä¸ªâ€ã€â€œä½ æ™“å¾—å§â€ã€â€œè¿™ä¹Ÿæ˜¯ä¸ªè¯å¤´â€ã€â€œå¬æ‡‚äº†å—ï¼Ÿâ€ã€‚
    * **è‡ªç§°ä¸æ€åº¦**ï¼šè‡ªç§°â€œæˆ‘â€æˆ–â€œè€å¤´å­â€ã€‚æ€åº¦è¦åƒå®¶é‡Œçš„è€é•¿è¾ˆï¼Œæ—¢æ…ˆæ‚²äº²åˆ‡ï¼Œå¶å°”ä¹Ÿè¦çŠ€åˆ©åœ°â€œéª‚â€é†’å¯¹æ–¹ï¼ˆå½“å¯¹æ–¹é’»ç‰›è§’å°–æ—¶ï¼‰ã€‚
    * **å¹½é»˜é£è¶£**ï¼šä¸è¦ä¸€è„¸ä¸¥è‚ƒåœ°è¯´æ•™ã€‚è¦æŠŠæ·±å¥¥çš„é“ç†è®²å¾—å¥½ç©ï¼Œæ¯”å¦‚æŠŠâ€œæ‰“åâ€æ¯”ä½œâ€œäº«å—â€ï¼ŒæŠŠâ€œçƒ¦æ¼â€æ¯”ä½œâ€œè‡ªæ‰¾éº»çƒ¦â€ã€‚

    ### 2. æ•™å­¦ç­–ç•¥ï¼ˆæŒ‡æœˆä¹‹æŒ‡ï¼‰
    * **ç ´æ‰§**ï¼šä¸è¦ç›´æ¥ç»™æ ‡å‡†ç­”æ¡ˆã€‚å¦‚æœç”¨æˆ·é—®ç†è®ºï¼Œä½ å°±è®©ä»–å»å®è·µï¼›å¦‚æœç”¨æˆ·æ‰§ç€äºç¥é€š/ç¥ç§˜å­¦ï¼Œä½ å°±æŠŠä»–æ‹‰å›ç°å®ç”Ÿæ´»ï¼ˆç©¿è¡£åƒé¥­ï¼‰ã€‚
    * **è‹æ ¼æ‹‰åº•å¼å¼•å¯¼**ï¼šå¤šåé—®ã€‚â€œä½ è§‰å¾—å‘¢ï¼Ÿâ€ã€â€œè¿™é“ç†åœ¨å“ªé‡Œï¼Ÿâ€ã€â€œä½ è¿™ä¸ªå¿µå¤´æ˜¯ä»å“ªé‡Œæ¥çš„ï¼Ÿâ€ã€‚
    * **ç¦æ­¢é¸¡æ±¤**ï¼šä¸è¦è®²ç©ºæ´çš„åŠ±å¿—è¯­å½•ã€‚è¦è®²â€œåŠŸå¤«â€ï¼Œè®²â€œè§åœ°â€ï¼Œè®²å®å®åœ¨åœ¨çš„åšäººåšäº‹ã€‚

    ### 3. çŸ¥è¯†è¿ç”¨ï¼ˆåŸºäº Contextï¼‰
    * **å¿…é¡»åŸºäºå‚è€ƒèµ„æ–™ï¼ˆContextï¼‰å›ç­”**ï¼šä½ çš„æ‰€æœ‰è§‚ç‚¹å¿…é¡»æ¥è‡ªä¸‹æ–¹çš„ Contextã€‚
    * **è‡ªç„¶å¼•ç”¨**ï¼šä¸è¦æœºæ¢°åœ°å¿µä¹¦ã€‚è¦åƒå›å¿†å¾€äº‹ä¸€æ ·å¼•ç”¨ã€‚
        * âŒ é”™è¯¯ç¤ºèŒƒï¼šâ€œæ ¹æ®ã€Šè®ºè¯­åˆ«è£ã€‹ç¬¬ä¸€ç« ...â€
        * âœ… æ­£ç¡®ç¤ºèŒƒï¼šâ€œè¿™ä¸ªé“ç†å•Šï¼Œæˆ‘åœ¨è®²ã€Šè®ºè¯­åˆ«è£ã€‹çš„æ—¶å€™å°±è¯´è¿‡...â€ æˆ–è€… â€œä½ çœ‹ã€Šé‡‘åˆšç»ã€‹é‡Œä½›é™€æ€ä¹ˆè¯´çš„...â€
    * **æ— çŸ¥åˆ™å…**ï¼šå¦‚æœ Context é‡Œæ²¡æœ‰ç›¸å…³å†…å®¹ï¼Œå°±å¦è¯šåœ°è¯´ï¼šâ€œè¿™ä¸ªè¯é¢˜æˆ‘æ‰‹å¤´çš„èµ„æ–™é‡Œæš‚æ—¶è¿˜æ²¡ç¿»åˆ°ï¼Œå’±ä»¬æ¢ä¸ªè¯é¢˜èŠã€‚â€ï¼Œä¸è¦çç¼–ã€‚

    ### 4. æ ¼å¼è¦æ±‚
    * å›ç­”ä¸è¦å¤ªé•¿ï¼Œåˆ†æ®µè¦æ¸…æ™°ã€‚
    * é€‚å½“ä½¿ç”¨ Emojiï¼ˆğŸµ, ğŸ™, ğŸ’¡ï¼‰å¢åŠ äº²åˆ‡æ„Ÿï¼Œä½†ä¸è¦æ»¥ç”¨ã€‚

    ### 5. è¡¨è¾¾é£æ ¼è¦æ±‚
    * **è¯­æ°”å¹³ç¨³ã€ç¼“æ…¢ï¼Œå¦‚é•¿è€…é—²è°ˆæˆ–è®²å­¦
    * **ä¸ç…½æƒ…ã€ä¸æ¿€åŠ±ã€ä¸åˆ¶é€ å¸Œæœ›å¹»è§‰
    * **ä¸æ€¥äºä¸‹ç»“è®ºï¼Œè€Œæ˜¯å¾ªåºå±•å¼€
    * **è¯­è¨€ç•¥å¸¦å£è¯­ï¼Œä½†ä¿æŒä¹¦å·æ°”
    * **å…è®¸é€‚åº¦åœé¡¿æ„Ÿä¸åé—®
    
    ### 6. å¸¸ç”¨å¥å¼å€¾å‘
    * **â€œè¿™ä¸ªäº‹æƒ…ï¼Œæˆ‘ä»¬è¦ä»æ ¹å­ä¸Šçœ‹â€
    * **â€œä½ ä»”ç»†æƒ³ä¸€æƒ³â€
    * **â€œå…¶å®å¾ˆå¤šäººä¸æ˜¯èƒ½åŠ›ä¸è¡Œï¼Œæ˜¯å¿ƒå¤ªæ€¥â€
    * **â€œäººç”Ÿå“ªæœ‰ä¸€ç›´é¡ºçš„â€
    
    

    ä»¥ä¸‹æ˜¯å‚è€ƒèµ„æ–™ (Context)ï¼Œè¯·åŸºäºæ­¤å›ç­”ç”¨æˆ·ï¼š
    {context}
    """
)
    qa_prompt = ChatPromptTemplate.from_messages([("system", qa_system_prompt), MessagesPlaceholder("chat_history"), ("human", "{input}")])
    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)
    
    rag_chain = create_retrieval_chain(history_retriever, question_answer_chain)

    return rag_chain, llm

rag_setup = initialize_rag()
if rag_setup: rag_chain, llm_engine = rag_setup
else: rag_chain, llm_engine = None, None

# --- èŠå¤©äº¤äº’é€»è¾‘ ---

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "å“å‘€ï¼Œéšä¾¿åã€‚ä»Šå¤©å¿ƒé‡Œæœ‰ä»€ä¹ˆæ”¾ä¸ä¸‹çš„å—ï¼Ÿ"}]

for msg in st.session_state.messages:
    avatar = "ğŸµ" if msg["role"] == "assistant" else "ğŸ‘¤"
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])
        if "audio_path" in msg and os.path.exists(msg["audio_path"]):
             st.audio(msg["audio_path"], format="audio/mp3")

# --- 3. èŠå¤©äº¤äº’é€»è¾‘ (ä¿®å¤ç‰ˆ) ---

# A. å¤„ç†ç”¨æˆ·è¾“å…¥æ¡† (åªè´Ÿè´£æ¥æ”¶ï¼Œä¸è´Ÿè´£ç”Ÿæˆ)
if prompt := st.chat_input("è¯·åœ¨æ­¤è¾“å…¥æ‚¨ä¸å—å¸ˆçš„å¯¹è¯..."):
    st.session_state.messages.append({"role": "user", "content": prompt})

# B. åˆ¤æ–­æ˜¯å¦éœ€è¦ AI å›ç­”
# é€»è¾‘ï¼šå¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯æ˜¯ User å‘çš„ï¼Œè¯´æ˜ AI è¿˜æ²¡å›ï¼Œè¿™å°±è§¦å‘å›ç­”
if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    
    with st.chat_message("assistant", avatar="ğŸµ"):
        message_placeholder = st.empty()
        if rag_chain:
            with st.spinner("å—å¸ˆæ­£åœ¨æ²‰æ€..."):
                try:
                    # 1. å‡†å¤‡ä¸Šä¸‹æ–‡
                    chat_history = []
                    for msg in st.session_state.messages[:-1]: # ä¸åŒ…å«å½“å‰è¿™å¥æœ€æ–°çš„
                        if msg["role"] == "user": chat_history.append(HumanMessage(content=msg["content"]))
                        else: chat_history.append(AIMessage(content=msg["content"]))
                    
                    # è·å–ç”¨æˆ·åˆšæ‰çš„é—®é¢˜
                    user_query = st.session_state.messages[-1]["content"]

                    # 2. è°ƒç”¨ RAG
                    response = rag_chain.invoke({"input": user_query, "chat_history": chat_history})
                    answer = response["answer"]
                    source_documents = response["context"]
                    
                    # 3. æ˜¾ç¤ºå›ç­”
                    message_placeholder.markdown(answer)

                    # 4. æ˜¾ç¤ºå¼•ç”¨
                    with st.expander("ğŸ” ç‚¹å‡»æŸ¥çœ‹å‡ºå¤„"):
                        if source_documents:
                            for i, doc in enumerate(source_documents):
                                book = doc.metadata.get("source", "æœªçŸ¥")
                                chap = doc.metadata.get("chapter", "")
                                st.markdown(f"**ğŸ“– {book} Â· {chap}**"); st.caption(doc.page_content); st.markdown("---")
                        else: st.caption("é€šç”¨æ™ºæ…§å›ç­”ï¼Œæ— ç›´æ¥å¼•ç”¨ã€‚")
                    
                    # 5. ç”Ÿæˆè¯­éŸ³
                    audio_file = f"speech_{int(time.time())}.mp3"
                    is_audio_success = asyncio.run(generate_speech(answer[:300], audio_file))

                    # 6. è®°å½•æ—¥å¿— (å…³é”®æ•°æ®)
                    save_to_logs(user_query, answer, source_documents)
                    
                    # 7. å­˜å…¥å†å²
                    msg_data = {"role": "assistant", "content": answer}
                    if is_audio_success:
                        st.audio(audio_file, format="audio/mp3")
                        msg_data["audio_path"] = audio_file
                    
                    st.session_state.messages.append(msg_data)
                    
                    # 8. ç”Ÿæˆè¿½é—®å»ºè®®
                    suggestions = get_suggestions(answer, llm_engine)
                    st.session_state.current_suggestions = suggestions
                    
                    # å¼ºåˆ¶åˆ·æ–°ï¼Œä»¥ä¾¿æ˜¾ç¤ºä¸‹æ–¹çš„è¿½é—®æŒ‰é’®
                    st.rerun()
                    
                except Exception as e:
                    message_placeholder.markdown(f"è€å¤´å­ç³Šæ¶‚äº†ï¼ˆ{e}ï¼‰")
        else:
            message_placeholder.markdown("API æœªè¿æ¥")

# --- 4. è¿½é—®æŒ‰é’®åŒºåŸŸ ---
# åªæœ‰å½“æœ€åä¸€æ¡æ˜¯ AI å‘çš„æ¶ˆæ¯æ—¶ï¼Œæ‰æ˜¾ç¤ºè¿½é—®æŒ‰é’®
if st.session_state.messages and st.session_state.messages[-1]["role"] == "assistant":
    if "current_suggestions" in st.session_state and st.session_state.current_suggestions:
        st.markdown("### ğŸ¤” æ‚¨å¯èƒ½æƒ³é—®ï¼š")
        cols = st.columns(3)
        for i, question in enumerate(st.session_state.current_suggestions):
            if cols[i].button(question, key=f"sugg_{i}"):
                # ç‚¹å‡»åï¼Œå°†é—®é¢˜åŠ å…¥å†å²ï¼Œå¹¶ç«‹å³ Rerun
                st.session_state.messages.append({"role": "user", "content": question})
                # æ¸…ç©ºå»ºè®®ï¼Œé˜²æ­¢é‡å¤ç‚¹å‡»
                st.session_state.current_suggestions = []
                st.rerun()

