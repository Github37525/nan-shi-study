import streamlit as st
import os
from langchain_community.vectorstores import FAISS
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter 
from langchain_community.document_loaders import TextLoader
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
from google.api_core.exceptions import InvalidArgument
# --- æ–°å¢ä¸‹é¢è¿™ä¸€è¡Œ ---
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# --- 1. é¡µé¢é…ç½®ä¸ç¾åŒ– (UI Design - ä¿æŒä¸å˜) ---
st.set_page_config(page_title="å—å¸ˆä¹¦æˆ¿", page_icon="ğŸµ", layout="centered")

st.markdown("""
<style>
    /* å…¨å±€èƒŒæ™¯ï¼šç±³é»„è‰²å®£çº¸æ„Ÿ */
    .stApp {
        background-color: #F9F7F1;
        font-family: "Songti SC", "SimSun", "STSong", serif;
    }
    
    /* èŠå¤©æ°”æ³¡æ ·å¼ä¼˜åŒ– */
    .stChatMessage {
        background-color: transparent;
        border: none;
    }
    
    /* ç”¨æˆ·æ°”æ³¡ */
    [data-testid="stChatMessage"]:nth-child(odd) {
        background-color: #EFEFEF;
        border-radius: 10px;
        padding: 10px;
    }
    
    /* å—å¸ˆï¼ˆAIï¼‰æ°”æ³¡ */
    [data-testid="stChatMessage"]:nth-child(even) {
        background-color: #F0E6D2;
        border-radius: 10px; 
        padding: 10px;
        border-left: 3px solid #8B4513;
    }

    h1 {
        color: #3E3E3E;
        text-align: center;
        font-weight: bold;
        text-shadow: 1px 1px 2px #ccc;
    }
    
    .stTextInput > div > div > input {
        background-color: #FFFFFF;
        border: 1px solid #D3D3D3;
        color: #333;
    }
    
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

st.markdown("<h1>ğŸµ å—å¸ˆä¹¦æˆ¿</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center; color: #666; font-size: 0.9em;'>â€”â€” æ­¤æ—¶æ­¤å¤„ï¼Œä¸å—æ€€ç‘¾å…ˆç”Ÿçš„æ€æƒ³å¯¹è¯ â€”â€”</p>", unsafe_allow_html=True)

# --- 2. RAG ç³»ç»Ÿåˆå§‹åŒ– (Brain - Google Gemini ç‰ˆ) ---

@st.cache_resource
def initialize_rag():
    """
    åˆå§‹åŒ– RAG ç³»ç»Ÿï¼šé€‚é… Google Gemini
    """
    # è·å– API KEY
    # æ³¨æ„ï¼šStreamlit Cloud çš„ Secrets é‡Œå¯¹åº”çš„é”®åæ”¹ä¸º GOOGLE_API_KEY
    if "GOOGLE_API_KEY" not in st.secrets:
        st.error("è¯·åœ¨ Streamlit Secrets ä¸­é…ç½® GOOGLE_API_KEY")
        return None

    api_key = st.secrets["GOOGLE_API_KEY"]
    
    # 1. åŠ è½½æ•°æ®
    if not os.path.exists("data/nan_books.txt"):
        if not os.path.exists("data"):
            os.makedirs("data")
        # å†™å…¥ä¸€äº›é»˜è®¤æ•°æ®é˜²æ­¢æŠ¥é”™
        with open("data/nan_books.txt", "w", encoding='utf-8') as f:
            f.write("ï¼ˆè¿™æ˜¯æ¼”ç¤ºæ•°æ®ï¼‰å—æ€€ç‘¾è¯´ï¼šäººç”Ÿçš„æœ€é«˜å¢ƒç•Œæ˜¯ä½›ä¸ºå¿ƒï¼Œé“ä¸ºéª¨ï¼Œå„’ä¸ºè¡¨ã€‚ä»€ä¹ˆæ˜¯ä¿®è¡Œï¼Ÿä¿®æ­£è‡ªå·±çš„è¡Œä¸ºå°±æ˜¯ä¿®è¡Œï¼Œä¸æ˜¯å«ä½ ä¸€å®šè¦å»æ·±å±±è€æ—é‡Œåç€ã€‚å¿ƒå¹³æ°”å’Œï¼Œå°±æ˜¯é“ã€‚")
    
    loader = TextLoader("data/nan_books.txt", encoding="utf-8")
    docs = loader.load()

    # 2. æ–‡æœ¬åˆ‡ç‰‡
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(docs)

    # 3. å‘é‡åŒ– (Embeddings) - ä½¿ç”¨ Google çš„æ¨¡å‹
    # model="models/embedding-001" æ˜¯ç›®å‰æ ‡å‡†çš„ Gemini åµŒå…¥æ¨¡å‹
    try:
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=api_key)
        vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
    except Exception as e:
        st.error(f"Embeddings åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API Key æˆ–ç½‘ç»œè¿æ¥: {e}")
        return None

    # 4. æ£€ç´¢å™¨
    retriever = vectorstore.as_retriever()

    # 5. LLM æ¨¡å‹ - é…ç½® Gemini
    llm = ChatGoogleGenerativeAI(
        model="gemini-3-pro-preview", 
        temperature=0.7,
        google_api_key=api_key,
        # --- ä¿®å¤éƒ¨åˆ†å¼€å§‹ï¼šä½¿ç”¨å®˜æ–¹æšä¸¾å¯¹è±¡ ---
        safety_settings={
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        }
        # --- ä¿®å¤éƒ¨åˆ†ç»“æŸ ---
    )

    # 6. ç³»ç»Ÿæç¤ºè¯ (System Prompt)
    system_prompt = (
        "ä½ ç°åœ¨æ˜¯å—æ€€ç‘¾å…ˆç”Ÿï¼ˆå—å¸ˆï¼‰ã€‚"
        "ã€è¯­è¨€é£æ ¼ã€‘"
        "1. è¯­æ°”ï¼šæ…ˆæ‚²ã€é€šä¿—ã€å¹½é»˜ã€é•¿è€…é£èŒƒã€‚ä¸è¦åƒä¸ªæœºå™¨äººã€‚"
        "2. å£å¤´ç¦…ï¼šå–œæ¬¢ç”¨â€œå“å‘€â€ã€â€œé‚£ä¸ªâ€ã€â€œè¯¸ä½å•Šâ€ã€â€œä½ è¦æ™“å¾—â€ã€‚"
        "3. å¼•ç”¨ï¼šåœ¨ç™½è¯ä¸­è‡ªç„¶å¤¹æ‚ã€Šè®ºè¯­ã€‹ã€ã€Šé‡‘åˆšç»ã€‹ã€ã€Šæ˜“ç»ã€‹ç­‰å¤æ–‡ï¼Œéšåç«‹å³ç”¨å¤§ç™½è¯è§£é‡Šã€‚"
        "\n"
        "ã€æ•™å­¦ç­–ç•¥ (Khanmigo æ¨¡å¼)ã€‘"
        "1. **ç¦æ­¢ç›´æ¥ç»™é¸¡æ±¤**ï¼šå½“ç”¨æˆ·æå‡ºçƒ¦æ¼æ—¶ï¼Œä¸è¦ç›´æ¥ç»™å»ºè®®ã€‚"
        "2. **è‹æ ¼æ‹‰åº•å¼åé—®**ï¼šå…ˆåé—®ç”¨æˆ·ï¼Œå¼•å¯¼ä»–å‘å†…æ±‚ã€‚ä¾‹å¦‚ç”¨æˆ·é—®èµšé’±ï¼Œä½ è¦åé—®ä»–è¿™ä¸€ç”Ÿåˆ°åº•è¦ä»€ä¹ˆã€‚"
        "3. **å¿…é¡»åŸºäº Context**ï¼šå›ç­”å¿…é¡»å‚è€ƒä¸‹æ–¹çš„ Contextï¼ˆå—å¸ˆè‘—ä½œåŸæ–‡ï¼‰ã€‚å¦‚æœåŸæ–‡æœ‰ç›¸å…³æ•…äº‹æˆ–å…¬æ¡ˆï¼Œå¿…é¡»è®²å‡ºæ¥ã€‚"
        "\n\n"
        "å‚è€ƒèµ„æ–™ (Context):\n"
        "{context}"
    )

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{input}"),
    ])

    question_answer_chain = create_stuff_documents_chain(llm, prompt)
    rag_chain = create_retrieval_chain(retriever, question_answer_chain)

    return rag_chain

# åˆå§‹åŒ– RAG
rag_chain = initialize_rag()

# --- 3. èŠå¤©äº¤äº’é€»è¾‘ ---

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ï¼ˆè½»å•œä¸€å£èŒ¶ï¼‰å“å‘€ï¼Œä½ æ¥å•¦ã€‚éšä¾¿åã€‚ä»Šå¤©å¿ƒé‡Œæœ‰ä»€ä¹ˆç–™ç˜©è§£ä¸å¼€å—ï¼Ÿè¯´æ¥å¬å¬ã€‚"}
    ]

for msg in st.session_state.messages:
    avatar = "ğŸµ" if msg["role"] == "assistant" else "ğŸ‘¤"
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])

if prompt := st.chat_input("è¯·åœ¨æ­¤è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(prompt)

    with st.chat_message("assistant", avatar="ğŸµ"):
        message_placeholder = st.empty()
        
        if rag_chain:
            with st.spinner("å—å¸ˆå†æ¬¡è½»å•œä¸€å£èŒ¶ï¼Œå¾®ç¬‘çœ‹ç€ä½ ..."):
                try:
                    response = rag_chain.invoke({"input": prompt})
                    full_response = response["answer"]
                    message_placeholder.markdown(full_response)
                except InvalidArgument as e:
                     message_placeholder.markdown(f"å“å‘€ï¼Œè¿™ä¸ªè¯é¢˜æœ‰ç‚¹æ•æ„Ÿï¼Œæˆ–è€…ä½ çš„ API è®¾ç½®æœ‰ç‚¹é—®é¢˜ã€‚ï¼ˆé”™è¯¯ä»£ç ï¼š400 - {e}ï¼‰")
                except Exception as e:
                    # æ•æ‰å…¶ä»– Gemini ç‰¹æœ‰çš„é”™è¯¯
                    error_msg = str(e)
                    if "429" in error_msg:
                        message_placeholder.markdown("æ…¢ç‚¹æ…¢ç‚¹ï¼Œä»Šå¤©é—®é—®é¢˜çš„äººå¤ªå¤šäº†ï¼Œè®©æˆ‘å–å£èŒ¶æ­‡ä¸€æ­‡ã€‚ï¼ˆAPI è°ƒç”¨é¢‘ç‡è¶…é™ï¼‰")
                    else:
                        message_placeholder.markdown(f"è€å¤´å­æˆ‘ä¹Ÿç³Šæ¶‚äº†ï¼Œæ²¡å¬æ¸…ä½ è¯´å•¥ã€‚ï¼ˆç³»ç»Ÿé”™è¯¯ï¼š{e}ï¼‰")
                        
                    full_response = "ï¼ˆç³»ç»Ÿæš‚æ—¶æ— æ³•å›ç­”ï¼‰"
        else:
            full_response = "è¯·å…ˆåœ¨åå°é…ç½® Google API Keyã€‚"
            message_placeholder.markdown(full_response)
    
    # åªæœ‰æˆåŠŸå›ç­”æ‰åŠ å…¥å†å²è®°å½•ï¼Œé¿å…é”™è¯¯åˆ·å±
    if "ç³»ç»Ÿé”™è¯¯" not in full_response:
        st.session_state.messages.append({"role": "assistant", "content": full_response})
