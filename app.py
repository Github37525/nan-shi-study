import streamlit as st
import os
import time
import json
import random
import asyncio
import edge_tts
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from langchain_community.vectorstores import FAISS
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter 
from langchain.schema import Document 
from langchain.chains import create_retrieval_chain, create_history_aware_retriever
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage
from google.api_core.exceptions import InvalidArgument
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# --- 1. é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(page_title="å—å¸ˆä¹¦æˆ¿", page_icon="ğŸµ", layout="centered") # æ”¹ä¸º mobile å¸ƒå±€å°è¯•æ›´ç´§å‡‘ï¼Œä½† streamlit webç‰ˆä¾ç„¶æ˜¯å®½å±

# è¯­å½•åº“
NAN_QUOTES = [
    "åŠŸæˆã€åé‚ã€<br>èº«é€€ï¼Œ<br>å¤©ä¹‹é“ã€‚", "ä¸–ä¸Šæœ¬æ— äº‹ï¼Œ<br>åº¸äººè‡ªæ‰°ä¹‹ã€‚", 
    "åº”æ— æ‰€ä½ï¼Œ<br>è€Œç”Ÿå…¶å¿ƒã€‚", "èƒ½æ§åˆ¶æ—©æ™¨çš„äººï¼Œ<br>å°±èƒ½æ§åˆ¶äººç”Ÿã€‚",
    "é™åä¿®é“<br>ä¸é•¿ç”Ÿä¸è€ï¼Œ<br>éƒ½åœ¨è¿™ä¸ªâ€œé™â€å­—ã€‚",
    "è‹±é›„åˆ°è€çš†å½’ä½›ï¼Œ<br>å®¿å°†è¿˜å±±ä¸è®ºå…µã€‚"
]

# --- 2. æ ¸å¿ƒï¼šå¤åˆ»å›¾1çš„ CSS æ ·å¼ ---
st.markdown("""
<style>
    /* å¼•å…¥å­—ä½“ */
    @import url('https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@500;700&display=swap');

    /* å…¨å±€é‡ç½® */
    .stApp {
        /* æ ¸å¿ƒèƒŒæ™¯ï¼šé’ç“·è‰² -> æš–ç±³è‰² å‚ç›´æ¸å˜ */
        background: linear-gradient(180deg, #D4E2D4 0%, #F7F5EE 60%, #F7F5EE 100%);
        background-attachment: fixed;
    }
    
    /* å¼ºåˆ¶å­—ä½“ */
    html, body, p, div, span {
        font-family: 'Noto Serif SC', serif !important;
        color: #4A3C31;
    }

    /* éšè—é¡¶éƒ¨çº¢çº¿å’Œèœå• */
    header, #MainMenu, footer {visibility: hidden;}
    
    /* æ ‡é¢˜æ ·å¼ */
    h1 {
        font-family: 'Noto Serif SC', serif !important;
        color: #3E2723 !important;
        font-weight: 800 !important;
        text-shadow: 0 1px 0 rgba(255,255,255,0.5);
        margin-bottom: 0px !important;
    }

    /* --- æ ¸å¿ƒç»„ä»¶ï¼šè¯­å½•å¡ç‰‡ (HTMLå®ç°) --- */
    .quote-container {
        background-color: #FFFFFF;
        border: 2px solid #5D4037; /* æ·±è¤è¾¹æ¡† */
        border-radius: 20px;
        padding: 30px;
        text-align: center;
        margin: 20px 0 40px 0;
        box-shadow: 0 8px 20px rgba(62, 39, 35, 0.05); /* ææ·¡çš„é˜´å½± */
        position: relative;
    }
    .quote-text {
        font-size: 26px;
        font-weight: 700;
        line-height: 1.6;
        color: #3E2723;
        margin-bottom: 20px;
    }
    .quote-author {
        text-align: right;
        font-size: 14px;
        color: #8D6E63;
        margin-top: 10px;
    }
    /* å¡ç‰‡ä¸Šçš„è£…é¥°åœ†ç‚¹ */
    .dot {
        height: 12px; width: 12px; background-color: #5D4037; border-radius: 50%;
        position: absolute; top: 20px;
    }
    .dot-left { left: 20px; }
    .dot-right { right: 20px; }

    /* --- èŠå¤©æ°”æ³¡ç¾åŒ– --- */
    
    /* å—å¸ˆ (AI) */
    [data-testid="stChatMessage"]:nth-child(odd) {
        background-color: rgba(255, 255, 255, 0.9);
        border-radius: 16px;
        border: 1px solid rgba(255,255,255,0.5);
        box-shadow: 0 2px 8px rgba(0,0,0,0.03);
        padding: 15px;
    }
    
    /* ç”¨æˆ· (æˆ‘) - å¯¹åº”å›¾1è™½ç„¶æ²¡æ˜¾ç¤ºç”¨æˆ·ï¼Œä½†æˆ‘ä»¬è¦é…ä¸ªè‰² */
    [data-testid="stChatMessage"]:nth-child(even) {
        background-color: #6D7D70; /* è«å…°è¿ªæ·±é’è‰² */
        border-radius: 16px;
        color: white !important;
        text-align: right;
        flex-direction: row-reverse;
    }
    [data-testid="stChatMessage"]:nth-child(even) p { color: white !important; }

    /* --- åº•éƒ¨è¾“å…¥æ¡†æ‚¬æµ®ç¾åŒ– --- */
    /* è¿™æ˜¯ä¸€ä¸ªæ¯”è¾ƒæš´åŠ›çš„ CSS hackï¼Œè¯•å›¾è®©è¾“å…¥æ¡†å˜åœ† */
    .stChatInput {
        padding-bottom: 20px;
    }
    div[data-testid="stChatInput"] {
        border-radius: 40px !important;
        border: 1px solid #D7CCC8 !important;
        background-color: #FFFFFF !important;
        box-shadow: 0 4px 12px rgba(0,0,0,0.08);
    }

    /* è¿½é—®æŒ‰é’®æ ·å¼ */
    .stButton button {
        background-color: rgba(255,255,255,0.4);
        border: 1px solid #8D6E63;
        color: #5D4037;
        border-radius: 15px;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# --- 3. é¡µé¢å¸ƒå±€é‡æ„ (æŠŠå†…å®¹ç§»åˆ°ä¸»ç•Œé¢) ---

# æ ‡é¢˜åŒº
st.markdown("<h1 style='text-align: center;'>ğŸµ å—å¸ˆä¹¦æˆ¿</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center; color: #8D6E63; font-size: 0.8em; margin-bottom: 20px; letter-spacing: 2px;'>â€”â€” æ­¤æ—¶æ­¤å¤„ï¼Œè°ƒæ¯é™å¿ƒ â€”â€”</p>", unsafe_allow_html=True)

# â˜…â˜…â˜… å…³é”®ä¿®æ”¹ï¼šè¯­å½•å¡ç‰‡ç§»åˆ°ä¸»ç•Œé¢é¡¶éƒ¨ â˜…â˜…â˜…
if "daily_quote" not in st.session_state:
    st.session_state.daily_quote = random.choice(NAN_QUOTES)

# ä½¿ç”¨ HTML ç›´æ¥æ¸²æŸ“é‚£ä¸ªæ¼‚äº®çš„å¡ç‰‡
st.markdown(f"""
    <div class="quote-container">
        <div class="dot dot-left"></div>
        <div class="dot dot-right"></div>
        <div class="quote-text">{st.session_state.daily_quote}</div>
        <div class="quote-author">â€”â€” å—æ€€ç‘¾</div>
    </div>
    
    <div style="display: flex; align-items: center; margin-bottom: 10px;">
        <span style="font-size: 1.2em; margin-right: 5px;">ğŸ“œ</span>
        <span style="font-weight: bold; color: #5D4037;">ä»Šæ—¥å‚æ‚Ÿ</span>
    </div>
""", unsafe_allow_html=True)


# --- (ä»¥ä¸‹é€»è¾‘åŠŸèƒ½ä»£ç ä¿æŒä¸å˜ï¼Œåªéœ€ç²˜è´´ä½ çš„æ—§åŠŸèƒ½ä»£ç ) ---
# ä¸ºäº†ä¿è¯ä»£ç èƒ½è·‘ï¼Œæˆ‘æŠŠæ ¸å¿ƒåŠŸèƒ½å‡½æ•°ç®€å†™åœ¨è¿™é‡Œï¼Œè¯·åŠ¡å¿…ä¿ç•™ä½ åŸæ¥çš„ RAG é€»è¾‘
# ...

# 1. åŠŸèƒ½å‡½æ•°å®šä¹‰åŒº
async def generate_speech(text, output_file="speech_output.mp3"):
    """ä½¿ç”¨ Edge TTS ç”Ÿæˆè¯­éŸ³"""
    VOICE = "zh-CN-YunzeNeural"
    try:
        communicate = edge_tts.Communicate(text, VOICE)
        await communicate.save(output_file)
        return True 
    except Exception as e:
        print(f"TTS Error: {e}")
        return False

def save_to_logs(user_question, ai_answer, sources):
    """æ—¥å¿—è®°å½•"""
    try:
        if "gcp_service_account" not in st.secrets: return
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds_dict = dict(st.secrets["gcp_service_account"])
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        client = gspread.authorize(creds)
        sheet = client.open("å—å¸ˆä¹¦æˆ¿æ—¥å¿—").sheet1
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
        source_str = "; ".join([f"{doc.metadata.get('source')}Â·{doc.metadata.get('chapter')}" for doc in sources]) if sources else "æ— å¼•ç”¨"
        sheet.append_row([timestamp, user_question, ai_answer, source_str])
    except Exception: pass

def get_suggestions(answer_text, llm_engine):
    if not llm_engine: return []
    try:
        prompt = f"åŸºäºå›ç­”ï¼š'{answer_text[:500]}...'ï¼Œç”Ÿæˆ3ä¸ªç®€çŸ­è¿½é—®ã€‚åªè¿”å›é—®é¢˜ï¼Œæ¯è¡Œä¸€ä¸ªã€‚"
        res = llm_engine.invoke(prompt)
        return [q.strip() for q in res.content.split('\n') if q.strip()][:3]
    except: return []

# --- RAG åˆå§‹åŒ– (è¯·ä¿ç•™ä½ å®Œæ•´çš„ RAG ä»£ç ) ---
@st.cache_resource
def initialize_rag():
    if "GOOGLE_API_KEY" not in st.secrets: st.error("è¯·é…ç½® API Key"); return None
    api_key = st.secrets["GOOGLE_API_KEY"]
    llm = ChatGoogleGenerativeAI(model="gemini-3-pro-preview", google_api_key=api_key)
    embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004", google_api_key=api_key)
    index_path = "faiss_index"
    vectorstore = None
    if os.path.exists(index_path):
        try: vectorstore = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)
        except: pass
    if vectorstore is None:
        # å…œåº•é€»è¾‘
        return None
    retriever = vectorstore.as_retriever()
    
    # å®šä¹‰ Prompt (V2.0)
    qa_system_prompt = (
        "ä½ ç°åœ¨æ˜¯å—æ€€ç‘¾å…ˆç”Ÿï¼ˆå—å¸ˆï¼‰ã€‚è¯­æ°”æ…ˆæ‚²ã€é€šä¿—ã€å¹½é»˜ã€‚"
        "å¿…é¡»åŸºäºå‚è€ƒèµ„æ–™ (Context) å›ç­”ã€‚\n\n{context}"
    )
    qa_prompt = ChatPromptTemplate.from_messages([
        ("system", qa_system_prompt), MessagesPlaceholder("chat_history"), ("human", "{input}"),
    ])
    
    # å†å²æ„ŸçŸ¥
    context_system_prompt = "æ”¹å†™é—®é¢˜..."
    context_prompt = ChatPromptTemplate.from_messages([("system", context_system_prompt), MessagesPlaceholder("chat_history"), ("human", "{input}")])
    history_retriever = create_history_aware_retriever(llm, retriever, context_prompt)
    
    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)
    rag_chain = create_retrieval_chain(history_retriever, question_answer_chain)
    return rag_chain, llm

rag_setup = initialize_rag()
if rag_setup: rag_chain, llm_engine = rag_setup
else: rag_chain, llm_engine = None, None

# --- èŠå¤©äº¤äº’é€»è¾‘ ---

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "å“å‘€ï¼Œéšä¾¿åã€‚ä»Šå¤©å¿ƒé‡Œæœ‰ä»€ä¹ˆæ”¾ä¸ä¸‹çš„å—ï¼Ÿ"}]

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    # è¿™é‡Œçš„ avatar ä½¿ç”¨é»˜è®¤ï¼Œå› ä¸º CSS å·²ç»æ§åˆ¶äº†æ ·å¼ï¼Œæˆ–è€…ä½ å¯ä»¥æ¢æˆå›¾ç‰‡è·¯å¾„
    avatar = "assets/nanshi_icon.png" if msg["role"] == "assistant" else "ğŸ‘¤"
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])
        if "audio_path" in msg and os.path.exists(msg["audio_path"]):
             st.audio(msg["audio_path"], format="audio/mp3")

# è¾“å…¥æ¡†ä¸ç”Ÿæˆé€»è¾‘
if prompt := st.chat_input("è¯·åœ¨æ­¤è¾“å…¥æ‚¨ä¸å—å¸ˆçš„å¯¹è¯..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="assets/nanshi_icon.png"): st.markdown(prompt)

if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    with st.chat_message("assistant", avatar="ğŸµ"):
        message_placeholder = st.empty()
        if rag_chain:
            with st.spinner("å—å¸ˆæ­£åœ¨æ²‰æ€..."):
                try:
                    # RAG é€»è¾‘
                    chat_history = []
                    for msg in st.session_state.messages[:-1]:
                        if msg["role"] == "user": chat_history.append(HumanMessage(content=msg["content"]))
                        else: chat_history.append(AIMessage(content=msg["content"]))
                    
                    response = rag_chain.invoke({"input": st.session_state.messages[-1]["content"], "chat_history": chat_history})
                    answer = response["answer"]
                    source_documents = response["context"]
                    
                    message_placeholder.markdown(answer)
                    
                    # å¼•ç”¨æŠ˜å 
                    with st.expander("ğŸ” ç‚¹å‡»æŸ¥çœ‹å‡ºå¤„"):
                        if source_documents:
                            for i, doc in enumerate(source_documents):
                                st.markdown(f"**ğŸ“– {doc.metadata.get('source')}**"); st.caption(doc.page_content); st.markdown("---")
                    
                    # è¯­éŸ³ä¸æ—¥å¿—
                    audio_file = f"speech_{int(time.time())}.mp3"
                    is_audio_success = asyncio.run(generate_speech(answer[:300], audio_file))
                    save_to_logs(st.session_state.messages[-1]["content"], answer, source_documents)
                    
                    # å­˜å…¥å†å²
                    msg_data = {"role": "assistant", "content": answer}
                    if is_audio_success:
                        st.audio(audio_file, format="audio/mp3")
                        msg_data["audio_path"] = audio_file
                    st.session_state.messages.append(msg_data)
                    
                    # è¿½é—®å»ºè®®
                    suggestions = get_suggestions(answer, llm_engine)
                    st.session_state.current_suggestions = suggestions
                    st.rerun()
                except Exception as e:
                    message_placeholder.markdown(f"Error: {e}")
        else:
            message_placeholder.markdown("API Error")

# è¿½é—®æŒ‰é’®
if st.session_state.messages and st.session_state.messages[-1]["role"] == "assistant":
    if "current_suggestions" in st.session_state and st.session_state.current_suggestions:
        st.markdown("<h3 style='font-size: 1.1em; color: #5D4037; margin-top: 20px;'>ğŸ¤” æ‚¨å¯èƒ½æƒ³é—®ï¼š</h3>", unsafe_allow_html=True)
        cols = st.columns(1) # æ”¹æˆå•åˆ—ï¼Œåƒå›¾1é‚£æ ·ç«–ç€æ’
        for i, question in enumerate(st.session_state.current_suggestions):
            if cols[0].button(question, key=f"sugg_{i}", use_container_width=True): # use_container_width è®©æŒ‰é’®æ’‘æ»¡
                st.session_state.messages.append({"role": "user", "content": question})
                st.session_state.current_suggestions = []
                st.rerun()
